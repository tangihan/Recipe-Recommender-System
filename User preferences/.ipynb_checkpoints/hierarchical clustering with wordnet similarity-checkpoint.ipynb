{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6035cb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "pos_tag = pd.read_csv('real_pos_tag.csv')\n",
    "\n",
    "\n",
    "pos_tag = pos_tag[\"col\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afa0f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from nltk.corpus import wordnet\n",
    " \n",
    "syn1 = wordnet.synsets('hello')[0]\n",
    "syn2 = wordnet.synsets('selling')[0]\n",
    " \n",
    "print (\"hello name :  \", syn1.name())\n",
    "print (\"selling name :  \", syn2.name())\n",
    "\n",
    "syn1.wup_similarity(syn2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4864ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop once \n",
    "syn_row = []\n",
    "word_row = []\n",
    "for tag in pos_tag:\n",
    "    try:\n",
    "        test = wordnet.synsets(tag)[0]\n",
    "        syn_row.append(test)\n",
    "        word_row.append(tag)\n",
    "    except:\n",
    "        print(\"word not in wordnet\",tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7ac6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "syn_matrix = []\n",
    "for i in range(len(syn_row)):\n",
    "    syn_row[i]\n",
    "    rowlist = []\n",
    "    rowlist.append(word_row[i])\n",
    "    for col in syn_row:\n",
    "        score = syn_row[i].wup_similarity(col)\n",
    "        rowlist.append(score)\n",
    "    syn_matrix.append(rowlist)\n",
    "    \n",
    "\n",
    "\n",
    "# creating df object with columns specified \n",
    "word_row = [\"tag\"] + word_row\n",
    "df = pd.DataFrame(syn_matrix, columns = word_row) \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e2f1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133a8169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wordnet is a database of semantic relations for words\n",
    "from nltk.corpus import wordnet\n",
    " \n",
    "syn1 = wordnet.synsets('hello')[0]\n",
    "syn2 = wordnet.synsets('selling')[0]\n",
    " \n",
    "print (\"hello name :  \", syn1.name())\n",
    "print (\"selling name :  \", syn2.name())\n",
    "\n",
    "\n",
    "# for i, row in reviews.iterrows():\n",
    "\n",
    "syn1.wup_similarity(syn2)\n",
    "sorted(syn1.common_hypernyms(syn2))\n",
    "\n",
    "ref = syn1.hypernyms()[0]\n",
    "print (\"Self comparison : \",\n",
    "       syn1.shortest_path_distance(ref))\n",
    " \n",
    "print (\"Distance of hello from greeting : \",\n",
    "       syn1.shortest_path_distance(syn2))\n",
    " \n",
    "print (\"Distance of greeting from hello : \",\n",
    "       syn2.shortest_path_distance(syn1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31c634b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"similarity_matrix.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd54fd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(word_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4b26b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = word_row\n",
    "sentences_split = [s.lower().split(' ') for s in sentences]\n",
    "\n",
    "import gensim\n",
    "model = gensim.models.Word2Vec(sentences_split, min_count=1)\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "\n",
    "l = linkage(model.wv.syn0, method='complete', metric='seuclidean')\n",
    "\n",
    "# calculate full dendrogram\n",
    "plt.figure(figsize=(25, 10))\n",
    "plt.title('Hierarchical Clustering Dendrogram')\n",
    "plt.ylabel('word')\n",
    "plt.xlabel('distance')\n",
    "\n",
    "dendrogram(\n",
    "    l,\n",
    "    leaf_rotation=90.,  # rotates the x axis labels\n",
    "    leaf_font_size=16.,  # font size for the x axis labels\n",
    "    orientation='left',\n",
    "    leaf_label_func=lambda v: str(model.wv.index2word[v])\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0541de",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839bb640",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_matrix = pd.read_csv(\"similarity_matrix.csv\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.preprocessing import StandardScaler, normalize\n",
    "from sklearn.metrics import silhouette_score\n",
    "import scipy.cluster.hierarchy as shc\n",
    "\n",
    "\n",
    "df_drop = df.drop(columns=\"tag\")\n",
    "\n",
    "plt.figure(figsize =(8, 8))\n",
    "plt.title('Visualising the data')\n",
    "Dendrogram = shc.dendrogram((shc.linkage(df_drop, method ='ward')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c3e217",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "cluster = AgglomerativeClustering(n_clusters=6, affinity='precomputed', linkage='complete')  \n",
    "cluster.fit_predict(df_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f64258",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.preprocessing import StandardScaler, normalize\n",
    "from sklearn.metrics import silhouette_score\n",
    "import scipy.cluster.hierarchy as shc\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "k = [2, 3, 4, 5, 6,7,8,9,10,11,12,13,14,15,16,17]\n",
    "  \n",
    "# Appending the silhouette scores of the different models to the list\n",
    "silhouette_scores = []\n",
    "for i in k:\n",
    "    clustermodel = AgglomerativeClustering(n_clusters = i)\n",
    "    score = silhouette_score(df_drop, clustermodel.fit_predict(df_drop))\n",
    "    silhouette_scores.append(score)\n",
    "    if i == 4 or i == 5 or i == 6:\n",
    "        print(i,\"silouette score\",score)\n",
    "plt.bar(k, silhouette_scores)\n",
    "plt.xlabel('Number of clusters', fontsize = 20)\n",
    "plt.ylabel('S(i)', fontsize = 20)\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207208a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = [4,5,6]\n",
    "  \n",
    "# Appending the silhouette scores of the different models to the list\n",
    "\n",
    "for i in k:\n",
    "    clustermodel = AgglomerativeClustering(n_clusters = i)\n",
    "    clustermodel.fit_predict(df_drop)\n",
    "\n",
    "# len(labels)\n",
    "    string =  str(i) + \"_no_cluster\" \n",
    "    df[string] = clustermodel.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c62230",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word = df[[\"tag\",\"4_no_cluster\",\"5_no_cluster\",\"6_no_cluster\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e29e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word.to_csv(\"tag_cluster.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc138b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "df_word = pd.read_csv(\"pos_tag_cluster.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3430c1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048cf188",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b96bd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "df_word = pd.read_csv(\"tag_cluster.csv\")\n",
    "ori_df = pd.read_csv('../Data/Raw Data/final_dataset_log.csv')\n",
    "\n",
    "i = 0\n",
    "j = 0\n",
    "wordcloudlist = []\n",
    "\n",
    "for index,row in ori_df.iterrows():\n",
    "    score = {0:0,1:0,2:0,3:0,4:0,5:0}\n",
    "#     k_cluster = [\"4_no_cluster\",\"5_no_cluster\",\"6_no_cluster\"]\n",
    "    k_cluster = [\"5_no_cluster\"]\n",
    "    for k in k_cluster:\n",
    "        \n",
    "        inside = False\n",
    "        for index2,posword_row in df_word.iterrows():\n",
    "            \n",
    "            if posword_row[\"tag\"] in row[\"review\"]:\n",
    "                inside = True\n",
    "                score[int(posword_row[k])] += 1\n",
    "                print(int(posword_row[k]))\n",
    "        \n",
    "        if inside:\n",
    "            print(\"inside\")\n",
    "            clusterbelong = max(score, key=score.get)\n",
    "\n",
    "\n",
    "            ori_df.loc[index,k] = clusterbelong\n",
    "        else:\n",
    "            print(\"not inside\")\n",
    "            ori_df.at[index,k] = np.nan\n",
    "\n",
    "        \n",
    "        \n",
    "        print(\"belongs in cluster: \")\n",
    "        print(clusterbelong)\n",
    "        print(\"-----------\")\n",
    "        print(score)\n",
    "\n",
    "    print(i,row[\"review\"])\n",
    "    print\n",
    "\n",
    "    \n",
    "ori_df.to_csv(\"final_dataset_cluster.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1273de2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_df.to_csv(\"final_dataset_cluster_5.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6decb0b9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    " ori_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78f5a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac3a938",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
