{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd859750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(97543, 17)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re \n",
    "\n",
    "reviews = pd.read_csv('../Data/Cleaned Data/final_dataset_cleaned.csv')\n",
    "\n",
    "reviews = reviews.dropna()\n",
    "\n",
    "\n",
    "print(reviews.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3421a498",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recipe_id</th>\n",
       "      <th>name</th>\n",
       "      <th>n_steps</th>\n",
       "      <th>n_ingredients</th>\n",
       "      <th>minutes</th>\n",
       "      <th>calories</th>\n",
       "      <th>total fat (PDV)</th>\n",
       "      <th>sugar (PDV)</th>\n",
       "      <th>sodium (PDV)</th>\n",
       "      <th>protein (PDV)</th>\n",
       "      <th>saturated fat (PDV)</th>\n",
       "      <th>carbohydrates (PDV)</th>\n",
       "      <th>user_id</th>\n",
       "      <th>date</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8694</td>\n",
       "      <td>margaret lefever s wonderful baked beans</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>315</td>\n",
       "      <td>326.2</td>\n",
       "      <td>13.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>8629</td>\n",
       "      <td>2001-04-22</td>\n",
       "      <td>I tried this recipe because it was the first s...</td>\n",
       "      <td>2</td>\n",
       "      <td>small quantity baked bean found starter doctor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5315</td>\n",
       "      <td>icy holiday punch</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1440</td>\n",
       "      <td>54.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8629</td>\n",
       "      <td>2001-04-24</td>\n",
       "      <td>I brought this to an office holiday party and ...</td>\n",
       "      <td>4</td>\n",
       "      <td>brought office holiday party everyone enjoyed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9014</td>\n",
       "      <td>cheesy potato skillet stuff</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>357.8</td>\n",
       "      <td>33.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11297</td>\n",
       "      <td>2001-06-18</td>\n",
       "      <td>What a great quick &amp; easy meal especially for ...</td>\n",
       "      <td>4</td>\n",
       "      <td>quick meal mushroom lovers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>580</td>\n",
       "      <td>garlic mushroom sauce</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>36</td>\n",
       "      <td>120.3</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11297</td>\n",
       "      <td>2001-06-25</td>\n",
       "      <td>Easy and tasty. Really made my steak special. ...</td>\n",
       "      <td>4</td>\n",
       "      <td>tasty steak special doreen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9492</td>\n",
       "      <td>chicken honey glazed</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>100</td>\n",
       "      <td>484.9</td>\n",
       "      <td>11.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>11297</td>\n",
       "      <td>2001-06-26</td>\n",
       "      <td>So easy and tasty. To make the clean-up even e...</td>\n",
       "      <td>4</td>\n",
       "      <td>tasty easier lined baking pan tinfoil sharing ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   recipe_id                                      name  n_steps  \\\n",
       "0       8694  margaret lefever s wonderful baked beans       10   \n",
       "1       5315                         icy holiday punch        5   \n",
       "2       9014               cheesy potato skillet stuff        5   \n",
       "3        580                     garlic mushroom sauce       10   \n",
       "4       9492                      chicken honey glazed        6   \n",
       "\n",
       "   n_ingredients  minutes  calories  total fat (PDV)  sugar (PDV)  \\\n",
       "0              6      315     326.2             13.0         75.0   \n",
       "1              6     1440      54.5              0.0         50.0   \n",
       "2              5       40     357.8             33.0          6.0   \n",
       "3              7       36     120.3              9.0          4.0   \n",
       "4              7      100     484.9             11.0        189.0   \n",
       "\n",
       "   sodium (PDV)  protein (PDV)  saturated fat (PDV)  carbohydrates (PDV)  \\\n",
       "0          14.0           28.0                 13.0                 16.0   \n",
       "1           0.0            0.0                  0.0                  4.0   \n",
       "2          22.0           30.0                 37.0                  8.0   \n",
       "3          30.0            3.0                 20.0                  1.0   \n",
       "4          20.0          110.0                  6.0                 16.0   \n",
       "\n",
       "   user_id        date                                             review  \\\n",
       "0     8629  2001-04-22  I tried this recipe because it was the first s...   \n",
       "1     8629  2001-04-24  I brought this to an office holiday party and ...   \n",
       "2    11297  2001-06-18  What a great quick & easy meal especially for ...   \n",
       "3    11297  2001-06-25  Easy and tasty. Really made my steak special. ...   \n",
       "4    11297  2001-06-26  So easy and tasty. To make the clean-up even e...   \n",
       "\n",
       "   rating                                     review_cleaned  \n",
       "0       2  small quantity baked bean found starter doctor...  \n",
       "1       4      brought office holiday party everyone enjoyed  \n",
       "2       4                         quick meal mushroom lovers  \n",
       "3       4                         tasty steak special doreen  \n",
       "4       4  tasty easier lined baking pan tinfoil sharing ...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c79be351",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.cluster import KMeans \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "import nltk\n",
    "import string\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "\n",
    "# email module has some useful functions\n",
    "import os, sys, email,re\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1fb940ba",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 7.27 GiB for an array with shape (97543, 10000) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-38baaea59e67>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mtf_idf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_idf_vectorizor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mtf_idf_norm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf_idf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mtf_idf_array\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_idf_norm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\sparse\\compressed.py\u001b[0m in \u001b[0;36mtoarray\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1029\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0morder\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1030\u001b[0m             \u001b[0morder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_swap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cf'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1031\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_toarray_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1032\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_contiguous\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_contiguous\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1033\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Output array must be C or F contiguous'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36m_process_toarray_args\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1200\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1201\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1202\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1203\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1204\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 7.27 GiB for an array with shape (97543, 10000) and data type float64"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "data = reviews['review_cleaned']\n",
    "\n",
    "\n",
    "tf_idf_vectorizor = TfidfVectorizer(stop_words = 'english',#tokenizer = tokenize_and_stem,\n",
    "                             max_features = 10000)\n",
    "tf_idf = tf_idf_vectorizor.fit_transform(data)\n",
    "tf_idf_norm = normalize(tf_idf)\n",
    "tf_idf_array = tf_idf_norm.toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ec3ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(tf_idf_array[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d03f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame(tf_idf_array, columns=tf_idf_vectorizor.get_feature_names()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0a38bf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aaa</th>\n",
       "      <th>aaaahhh</th>\n",
       "      <th>aaaahs</th>\n",
       "      <th>aaaarrrrh</th>\n",
       "      <th>aaah</th>\n",
       "      <th>aaahed</th>\n",
       "      <th>aaahhed</th>\n",
       "      <th>aabout</th>\n",
       "      <th>aagain</th>\n",
       "      <th>...</th>\n",
       "      <th>zuke</th>\n",
       "      <th>zukes</th>\n",
       "      <th>zuri</th>\n",
       "      <th>zurie</th>\n",
       "      <th>zwf</th>\n",
       "      <th>zwizzle</th>\n",
       "      <th>zwt</th>\n",
       "      <th>zwtii</th>\n",
       "      <th>zwtiii</th>\n",
       "      <th>zyliss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 20000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    aa  aaa  aaaahhh  aaaahs  aaaarrrrh  aaah  aaahed  aaahhed  aabout  \\\n",
       "0  0.0  0.0      0.0     0.0        0.0   0.0     0.0      0.0     0.0   \n",
       "1  0.0  0.0      0.0     0.0        0.0   0.0     0.0      0.0     0.0   \n",
       "2  0.0  0.0      0.0     0.0        0.0   0.0     0.0      0.0     0.0   \n",
       "3  0.0  0.0      0.0     0.0        0.0   0.0     0.0      0.0     0.0   \n",
       "4  0.0  0.0      0.0     0.0        0.0   0.0     0.0      0.0     0.0   \n",
       "\n",
       "   aagain  ...  zuke  zukes  zuri  zurie  zwf  zwizzle  zwt  zwtii  zwtiii  \\\n",
       "0     0.0  ...   0.0    0.0   0.0    0.0  0.0      0.0  0.0    0.0     0.0   \n",
       "1     0.0  ...   0.0    0.0   0.0    0.0  0.0      0.0  0.0    0.0     0.0   \n",
       "2     0.0  ...   0.0    0.0   0.0    0.0  0.0      0.0  0.0    0.0     0.0   \n",
       "3     0.0  ...   0.0    0.0   0.0    0.0  0.0      0.0  0.0    0.0     0.0   \n",
       "4     0.0  ...   0.0    0.0   0.0    0.0  0.0      0.0  0.0    0.0     0.0   \n",
       "\n",
       "   zyliss  \n",
       "0     0.0  \n",
       "1     0.0  \n",
       "2     0.0  \n",
       "3     0.0  \n",
       "4     0.0  \n",
       "\n",
       "[5 rows x 20000 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1a374c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Kmeans:\n",
    "    \"\"\" K Means Clustering\n",
    "    \n",
    "    Parameters\n",
    "    -----------\n",
    "        k: int , number of clusters\n",
    "        \n",
    "        seed: int, will be randomly set if None\n",
    "        \n",
    "        max_iter: int, number of iterations to run algorithm, default: 200\n",
    "        \n",
    "    Attributes\n",
    "    -----------\n",
    "       centroids: array, k, number_features\n",
    "       \n",
    "       cluster_labels: label for each data point\n",
    "       \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, k, seed = None, max_iter = 200):\n",
    "        self.k = k\n",
    "        self.seed = seed\n",
    "        if self.seed is not None:\n",
    "            np.random.seed(self.seed)\n",
    "        self.max_iter = max_iter\n",
    "        \n",
    "            \n",
    "    \n",
    "    def initialise_centroids(self, data):\n",
    "        \"\"\"Randomly Initialise Centroids\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        data: array or matrix, number_rows, number_features\n",
    "        \n",
    "        Returns\n",
    "        --------\n",
    "        centroids: array of k centroids chosen as random data points \n",
    "        \"\"\"\n",
    "        \n",
    "        initial_centroids = np.random.permutation(data.shape[0])[:self.k]\n",
    "        self.centroids = data[initial_centroids]\n",
    "\n",
    "        return self.centroids\n",
    "    def assign_clusters(self, data):\n",
    "        \"\"\"Compute distance of data from clusters and assign data point\n",
    "           to closest cluster.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        data: array or matrix, number_rows, number_features\n",
    "\n",
    "        Returns\n",
    "        --------\n",
    "        cluster_labels: index which minmises the distance of data to each\n",
    "        cluster\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        if data.ndim == 1:\n",
    "            data = data.reshape(-1, 1)\n",
    "\n",
    "        dist_to_centroid =  pairwise_distances(data, self.centroids, metric = 'euclidean')\n",
    "        self.cluster_labels = np.argmin(dist_to_centroid, axis = 1)\n",
    "\n",
    "        return  self.cluster_labels\n",
    "\n",
    "\n",
    "    def update_centroids(self, data):\n",
    "        \"\"\"Computes average of all data points in cluster and\n",
    "           assigns new centroids as average of data points\n",
    "\n",
    "        Parameters\n",
    "        -----------\n",
    "        data: array or matrix, number_rows, number_features\n",
    "\n",
    "        Returns\n",
    "        -----------\n",
    "        centroids: array, k, number_features\n",
    "        \"\"\"\n",
    "\n",
    "        self.centroids = np.array([data[self.cluster_labels == i].mean(axis = 0) for i in range(self.k)])\n",
    "\n",
    "        return self.centroids\n",
    "\n",
    "    def predict(self, data):\n",
    "        \"\"\"Predict which cluster data point belongs to\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        data: array or matrix, number_rows, number_features\n",
    "\n",
    "        Returns\n",
    "        --------\n",
    "        cluster_labels: index which minmises the distance of data to each\n",
    "        cluster\n",
    "        \"\"\"\n",
    "\n",
    "        return self.assign_clusters(data)\n",
    "\n",
    "    def fit_kmeans(self, data):\n",
    "        \"\"\"\n",
    "        This function contains the main loop to fit the algorithm\n",
    "        Implements initialise centroids and update_centroids\n",
    "        according to max_iter\n",
    "        -----------------------\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        instance of kmeans class\n",
    "\n",
    "        \"\"\"\n",
    "        self.centroids = self.initialise_centroids(data)\n",
    "\n",
    "        # Main kmeans loop\n",
    "        for iter in range(self.max_iter):\n",
    "\n",
    "            self.cluster_labels = self.assign_clusters(data)\n",
    "            self.centroids = self.update_centroids(data)          \n",
    "            if iter % 100 == 0:\n",
    "                print(\"Running Model Iteration %d \" %iter)\n",
    "        print(\"Model finished running\")\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0883e9e",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 14.5 GiB for an array with shape (97543, 20000) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-70f1a7efa624>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mNUM_COMPONENTS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2000\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mpca\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPCA\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNUM_COMPONENTS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mY_sklearn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf_idf_array\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mvariance_explained\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcumsum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpca\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexplained_variance_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\decomposition\\_pca.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    374\u001b[0m         \u001b[0mC\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mordered\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse\u001b[0m \u001b[1;34m'np.ascontiguousarray'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    375\u001b[0m         \"\"\"\n\u001b[1;32m--> 376\u001b[1;33m         \u001b[0mU\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mVt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    377\u001b[0m         \u001b[0mU\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mU\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_components_\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    378\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\decomposition\\_pca.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    395\u001b[0m                             'TruncatedSVD for a possible alternative.')\n\u001b[0;32m    396\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 397\u001b[1;33m         X = self._validate_data(X, dtype=[np.float64, np.float32],\n\u001b[0m\u001b[0;32m    398\u001b[0m                                 ensure_2d=True, copy=self.copy)\n\u001b[0;32m    399\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    419\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    420\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'no_validation'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 421\u001b[1;33m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    422\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    423\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    681\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    682\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmay_share_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marray_orig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 683\u001b[1;33m         \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    684\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    685\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 14.5 GiB for an array with shape (97543, 20000) and data type float64"
     ]
    }
   ],
   "source": [
    "\n",
    "NUM_COMPONENTS = 2000\n",
    "pca = PCA(NUM_COMPONENTS)\n",
    "Y_sklearn = pca.fit_transform(tf_idf_array)\n",
    "\n",
    "variance_explained = np.cumsum(pca.explained_variance_)\n",
    "\n",
    "print(len(Y_sklearn[0]))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 8))\n",
    "plt.plot(range(NUM_COMPONENTS),variance_explained, color='r')\n",
    "ax.grid(True)\n",
    "plt.xlabel(\"Number of components\")\n",
    "plt.ylabel(\"Cumulative explained variance\")\n",
    "# test_e = Kmeans(3, 1, 600)\n",
    "# fitted = test_e.fit_kmeans(Y_sklearn)\n",
    "# predicted_values = test_e.predict(Y_sklearn)\n",
    "\n",
    "# plt.scatter(Y_sklearn[:, 0], Y_sklearn[:, 1], c=predicted_values, s=50, cmap='viridis')\n",
    "\n",
    "# centers = fitted.centroids\n",
    "# plt.scatter(centers[:, 0], centers[:, 1],c='black', s=300, alpha=0.6);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1364f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "number_clusters = range(1, 7)\n",
    "\n",
    "kmeans = [KMeans(n_clusters=i, max_iter = 600) for i in number_clusters]\n",
    "kmeans\n",
    "\n",
    "score = [kmeans[i].fit(Y_sklearn).score(Y_sklearn) for i in range(len(kmeans))]\n",
    "score\n",
    "\n",
    "plt.plot(number_clusters, score)\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Elbow Method')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a35d2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_features_cluster(tf_idf_array, prediction, n_feats):\n",
    "    labels = np.unique(prediction)\n",
    "    dfs = []\n",
    "    for label in labels:\n",
    "        id_temp = np.where(prediction==label) # indices for each cluster\n",
    "        x_means = np.mean(tf_idf_array[id_temp], axis = 0) # returns average score across cluster\n",
    "        sorted_means = np.argsort(x_means)[::-1][:n_feats] # indices with top 20 scores\n",
    "        features = tf_idf_vectorizor.get_feature_names()\n",
    "        best_features = [(features[i], x_means[i]) for i in sorted_means]\n",
    "        df = pd.DataFrame(best_features, columns = ['features', 'score'])\n",
    "        dfs.append(df)\n",
    "    return dfs\n",
    "dfs = get_top_features_cluster(tf_idf_array, prediction, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08aca8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea524d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wordnet is a database of semantic relations for words\n",
    "from nltk.corpus import wordnet\n",
    " \n",
    "syn1 = wordnet.synsets('hello')[0]\n",
    "syn2 = wordnet.synsets('selling')[0]\n",
    " \n",
    "print (\"hello name :  \", syn1.name())\n",
    "print (\"selling name :  \", syn2.name())\n",
    "\n",
    "\n",
    "# for i, row in reviews.iterrows():\n",
    "\n",
    "syn1.wup_similarity(syn2)\n",
    "sorted(syn1.common_hypernyms(syn2))\n",
    "\n",
    "ref = syn1.hypernyms()[0]\n",
    "print (\"Self comparison : \",\n",
    "       syn1.shortest_path_distance(ref))\n",
    " \n",
    "print (\"Distance of hello from greeting : \",\n",
    "       syn1.shortest_path_distance(syn2))\n",
    " \n",
    "print (\"Distance of greeting from hello : \",\n",
    "       syn2.shortest_path_distance(syn1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4d0477",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
